{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xp81GSFN7uHY"
   },
   "source": [
    "# Deep Learning week - Day 3 - Google Colab\n",
    "\n",
    "\n",
    "### Exercise objetives\n",
    "- Train a CNN on Google Colab to speed up the model convergence\n",
    "- Design a CNN architecture on your own\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "For CNN, the training time of each epochs highly depends on : \n",
    "- the network architecture\n",
    "- the number of input data (which increases in case of data augmentation)\n",
    "- the shape of each image\n",
    "\n",
    "We have seen that even quite small images and standard achitectures lead to very long computational time. This is because the neural network are (by default) run on your CPU. On the other hand, GPUs can compute large operations in parallel, which is what we are interested in as within each batch, it is theoretically possible to compute the transformation of all the images in parallel (on the contrary, the backpropagation has to be done on all the images in the same time, so no real parallelization here). Let's use Google Colab to accelerate the model convergence thanks to Google GPUs.\n",
    "\n",
    "\n",
    "\n",
    "# Google Colab\n",
    "\n",
    "\n",
    "Google Colab is nothing more than a way to have online notebooks, with the possibility to use Google GPUs. The idea here is not to use it in production (as there are some limitations) but to use Google Colab to test and prototype new algorithms. This free access to GPU allows you to accelerate the computational time. \n",
    "\n",
    "So the first task is to open the notebook you are reading on Google Colab. To do so: \n",
    "- Open Google Colab [here](https://colab.research.google.com/)\n",
    "- Import a Notebook and select this file, the one you are currently reading.\n",
    "- Once open, you are now running a similar Notebook but in Google Colab.\n",
    "- **Change the runtime type to GPU (Go in Execution > Change the execution type).**\n",
    "\n",
    "Welcome to Google Colab! Do not forget that you can open any notebook in Google Colab (but it is not always worth it and working on your computer might be enough for many tasks - however, with images, we recommand to do it on Google Colab. Moreover, we will mention the exercises that are preferably done on Colab during the week).\n",
    "\n",
    "\n",
    "\n",
    "# Data loading & Preprocessing\n",
    "\n",
    "You have two options to load the data on Google Colab.\n",
    "\n",
    "\n",
    "### Option 1: Loading the data directly \n",
    "\n",
    "You can first get the data onto google Colab thanks to:\n",
    "\n",
    "`!wget https://wagon-public-datasets.s3.amazonaws.com/flowers-dataset.zip`,\n",
    "\n",
    "and then run \n",
    "\n",
    "`!unzip flowers-dataset.zip`\n",
    "\n",
    "This is a very easy option to load the data into your working directory.\n",
    "\n",
    "\n",
    "### Option 2: Adding the data to Google Drive.\n",
    "\n",
    "You can first download the data  from `https://wagon-public-datasets.s3.amazonaws.com/flowers-dataset.zip`. Then you have to add them to your Google Drive in a folder called `Deep_learning_data` (for instance) and run the following code in the notebook.: \n",
    "\n",
    "```\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "```\n",
    "\n",
    "The previous code will ask you to go to a given webpage where you copy the link and past it in the Colab form that will appear. Do so to load the data on Google Colab.\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "### In practice, option 1 or option 2?\n",
    "\n",
    "Why choosing this option over the first one? This can be of interest if you work in a project team, and update the data from time to time. By doing this, you can share the same data folder within a team, and be sure that everyone has the same at any time, even though someone changes it. The drawback is that Google Colab has now access to your Google Folder, which you might not be or not in favor of, depending on your sensibility.\n",
    "\n",
    "❓ **Question** ❓ Use one of the above method to load your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "Y1c4Xwno7uHm"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "riTyl7uf3YDC"
   },
   "source": [
    "❓ **Question** ❓ Depending on the `loading_method` you have used, load the data and store them in the appropriate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "hB0XEe6y7uH7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def load_flowers_data(loading_method):\n",
    "    if loading_method == 'colab':\n",
    "        data_path = '/content/drive/My Drive/Deep_learning_data/flowers'\n",
    "    elif loading_method == 'direct':\n",
    "        data_path = 'flowers/'\n",
    "    classes = {'daisy':0, 'dandelion':1, 'rose':2}\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for (cl, i) in classes.items():\n",
    "        images_path = [elt for elt in os.listdir(os.path.join(data_path, cl)) if elt.find('.jpg')>0]\n",
    "        for img in tqdm(images_path[:300]):\n",
    "            path = os.path.join(data_path, cl, img)\n",
    "            if os.path.exists(path):\n",
    "                image = Image.open(path)\n",
    "                image = image.resize((256, 256))\n",
    "                imgs.append(np.array(image))\n",
    "                labels.append(i)\n",
    "\n",
    "    X = np.array(imgs)\n",
    "    num_classes = len(set(labels))\n",
    "    y = to_categorical(labels, num_classes)\n",
    "\n",
    "    # Finally we shuffle:\n",
    "    p = np.random.permutation(len(X))\n",
    "    X, y = X[p], y[p]\n",
    "\n",
    "    first_split = int(len(imgs) /6.)\n",
    "    second_split = first_split + int(len(imgs) * 0.2)\n",
    "    X_test, X_val, X_train = X[:first_split], X[first_split:second_split], X[second_split:]\n",
    "    y_test, y_val, y_train = y[:first_split], y[first_split:second_split], y[second_split:]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, num_classes\n",
    "\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, let's start by some preprocessing\n",
    "\n",
    "❓ **Question** ❓ First check that all your images have the same size. How many colors do these images have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OOF7fVp27uI2"
   },
   "source": [
    "❓ **Question** ❓ Plot some images with the `imshow` function of matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR PLOT HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Do not forget to normalize the image intensities if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "\n",
    "❓ **Question** ❓ You have already run multiple CNN over the previous exercises. Here, you are on your own to design its architecture. A good practice is to start by having a very simple architecture. It insures that its running - and if there is a problem, fewer lines are easier to debug. Then, once you have a simple architecture, you can complexify your neural network to improve its performance.\n",
    "\n",
    "<details>\n",
    "   <summary>If you are not sure what the simple Neural network would look like, click >>HERE<< </summary>\n",
    "    <ul>\n",
    "        <li> A convolution layer with enough filters - choose the kernel size wisely as your data are quite large here</li>\n",
    "        <li> A Maxpooling layer </li>\n",
    "        <li> Flatten your output </li>\n",
    "        <li> Add the last layer accoding to your task</li>\n",
    "        \n",
    "</ul>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details>\n",
    "   <summary>If you are not sure what can improve the neural design, click >>HERE<< </summary>\n",
    "    Usually, Deep learners would do the following (in this order) : \n",
    "    <ul>\n",
    "        <li>Add a dense layer between the flattening and the last layer</li>\n",
    "        <li>More convolution & pooling layers: you can try 4 or each here</li>\n",
    "        <li>Change the size of your kernels and potentially other hyperparameters</li>\n",
    "        <li>Add some regularization (L1, L2 or Dropout) if you feel its overfitting</li>\n",
    "        <li>The rest is for you to try ;) </li>\n",
    "    </ul>\n",
    "</details>\n",
    "\n",
    "\n",
    "Do not forget to compile it and fit it on the train data (use the `validation_data` with the `X_val` and `y_val` instead of using the `validation_split` argument). Do not forget the early stopping criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Play a bit with your model to look at the effect of different architectures, especially by:\n",
    "- changing the number of convolution layers (associated to their maxpooling layer)\n",
    "- changing the number of filters\n",
    "- changing the kernel sizes\n",
    "- changing the padding and strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Transfer_learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
